{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining a class\n",
    "class NewCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    # defining sparsity\n",
    "    def __init__(self, sparsity):\n",
    "        self.sparsity=sparsity/100\n",
    "        \n",
    "    # main Function \n",
    "    def on_epoch_end(self,epochs,cd):\n",
    "        # Function to find threshold\n",
    "        def threshold_find(sparsity,weights):\n",
    "            index=int(sparsity*weights.shape[0])\n",
    "            threshold=(sorted(weights))[index]\n",
    "            return threshold\n",
    "        \n",
    "        check=False\n",
    "        for layers in reversed(self.model.layers):\n",
    "            a=self.model.get_layer(layers.name)    \n",
    "            e=a.get_weights()    # Taking layer wieghts\n",
    "            \n",
    "            if len(e)>0 and check == False: # to exclude layers with zero parameters and to skip the last layer\n",
    "                check=True\n",
    "                continue;\n",
    "                \n",
    "            if check==True and len(e)>0: \n",
    "                \n",
    "                if 'lstm' in layers.name : # checking layer name\n",
    "                    avg =np.average(e[1]**2,axis=0)+np.average(e[0]**2,axis=0) # avg there weights\n",
    "                    weights1=0\n",
    "                    units = e[1].shape[0]\n",
    "                    \n",
    "                    for i in range(0,4):\n",
    "                        weights1=weights1+avg[units*i:units*(i+1)] # because of 4 gates\n",
    "                    squared_sum =weights1/4\n",
    "                    threshold = threshold_find(self.sparsity,squared_sum) # finding threshold\n",
    "                    upper_threshold = (squared_sum > threshold)\n",
    "                    \n",
    "                    for i in range(0,4): # zeroing values below threshold\n",
    "                        e[0][:,units*i:units*(i+1)]= e[0][:,units*i:units*(i+1)]*upper_threshold\n",
    "                        e[1][:,units*i:units*(i+1)]= e[1][:,units*i:units*(i+1)]*upper_threshold\n",
    "                        e[2][units*i:units*(i+1)]= e[2][units*i:units*(i+1)]*upper_threshold\n",
    "                    a.set_weights(e) # setting weights back\n",
    "                \n",
    "                # repeating for dense and conv2d layer\n",
    "                    \n",
    "                if 'dense' in layers.name or 'conv2d' in layers.name or 'conv1d' in layers.name:\n",
    "                    avg = np.average(e[0]**2,axis=tuple(np.arange(0,len(e[0].shape)-1)))\n",
    "                    threshold = threshold_find(self.sparsity,avg)\n",
    "                    upper_threshold = (avg > threshold)\n",
    "                    e[0]=e[0]*upper_threshold\n",
    "                    e[1]=e[1]*upper_threshold\n",
    "                    a.set_weights(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-feec1d583c0e>, line 82)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-feec1d583c0e>\"\u001b[1;36m, line \u001b[1;32m82\u001b[0m\n\u001b[1;33m    shape=layers.output_shape\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Final compression\n",
    "delete_ind=[]\n",
    "layer_details={}\n",
    "allow=0\n",
    "check_flatten = False\n",
    "dense_flatten = np.array(None)\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "prunned_model = pruned_model.to_json() # converting model into json\n",
    "res = json.loads(prunned_model) \n",
    "i=0\n",
    "\n",
    "for layers in pruned_model.layers:\n",
    "    a=pruned_model.get_layer(layers.name) # getting weights\n",
    "    e=a.get_weights()\n",
    "    \n",
    "    if 'Flatten' in str(layers):\n",
    "        check_flatten= True\n",
    "        \n",
    "    #checking for layers with none parameters\n",
    "    if len(e)>0:\n",
    "        if 'lstm' in str(layers):\n",
    "            e[0] = np.delete(e[0],delete_ind,0)   # removing dimension from previous layers \n",
    "            \n",
    "            avg =np.average(e[1]**2,axis=0)+np.average(e[0]**2,axis=0)  # avg to find which filters to remove\n",
    "            weights1=0\n",
    "            units = e[1].shape[0]\n",
    "            \n",
    "            for j in range(0,4):\n",
    "                weights1=weights1+avg[units*j:units*(j+1)]\n",
    "            delete_ind = np.nonzero(weights1==0)\n",
    "            \n",
    "            \n",
    "            #removing weights \n",
    "            c= np.concatenate((delete_ind[0],delete_ind[0]+units,delete_ind[0]+units*2,delete_ind[0]+units*3))\n",
    "            e[0] = np.delete(e[0],c,1)\n",
    "            e[1] = np.delete(e[1],delete_ind,0)\n",
    "            e[1] = np.delete(e[1],c,1)\n",
    "            e[2] = np.delete(e[2],c,0)\n",
    "            \n",
    "            \n",
    "            # changing number of filters in model\n",
    "            if (layers.name==res['config']['layers'][i]['name']):\n",
    "                res['config']['layers'][i]['config']['units']=e[1].shape[0]\n",
    "                \n",
    "                \n",
    "            # repeating for the dense layer \n",
    "        if 'Dense' in str(layers):\n",
    "            if check_flatten == False:\n",
    "                e[0] = np.delete(e[0],delete_ind,(len(e[0].shape)-2))\n",
    "            else:\n",
    "                for k in range(0,shape[1]*shape[2]+1):\n",
    "                    dense_flatten = np.append(dense_flatten,delete_ind[0]+512*k)\n",
    "                    delete_ind = tuple(dense_flatten[1:])\n",
    "                    e[0] = np.delete(e[0],delete_ind,(len(e[0].shape)-2))\n",
    "                check_flatten = False\n",
    "            avg = np.average(e[0]**2,axis=tuple(np.arange(0,len(e[0].shape)-1)))\n",
    "            delete_ind = np.nonzero(avg==0)\n",
    "            e[0] = np.delete(e[0],delete_ind,(len(e[0].shape)-1))\n",
    "            e[1] = np.delete(e[1],delete_ind,0)\n",
    "            if (layers.name==res['config']['layers'][i]['name']):\n",
    "                if 'Dense' in str(layers):\n",
    "                    res['config']['layers'][i]['config']['units']=e[1].shape[0]\n",
    "                    \n",
    "            \n",
    "            # repeat for conv layer\n",
    "        if 'Conv2D' in str(layers) or 'Conv1D' in str(layers):\n",
    "            e[0] = np.delete(e[0],delete_ind,(len(e[0].shape)-2))\n",
    "            avg = np.average(e[0]**2,axis=tuple(np.arange(0,len(e[0].shape)-1)))\n",
    "            delete_ind = np.nonzero(avg==0)\n",
    "            e[0] = np.delete(e[0],delete_ind,(len(e[0].shape)-1))\n",
    "            e[1] = np.delete(e[1],delete_ind,0)\n",
    "            if (layers.name==res['config']['layers'][i]['name']):\n",
    "                res['config']['layers'][i]['config']['filters']=e[1].shape[0]\n",
    "                \n",
    "    \n",
    "        layer_details[layers.name] = {'weights':e}\n",
    "    try:\n",
    "        if check_flatten==False:\n",
    "            shape=layers.output_shape\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    res['config']['layers'][i]['config']['dtype']='float16' # quantization\n",
    "    i=i+1\n",
    "res=json.dumps(res)\n",
    "prunned_model = tf.keras.models.model_from_json(res) # converting back model from json to model\n",
    "\n",
    "# setting weights back\n",
    "for layers in prunned_model.layers:\n",
    "    if 'lstm' in str(layers) or 'Dense' in str(layers) or 'Conv2D' in str(layers) or 'Conv1D' in str(layers):\n",
    "        a=prunned_model.get_layer(layers.name)\n",
    "        e=a.get_weights()\n",
    "        e=layer_details[layers.name]['weights']\n",
    "        a.set_weights(e)        \n",
    "        \n",
    "prunned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_x,train_label,epochs=1,validation_split=0.05,batch_size=64,callbacks=[MyCustomCallback(#provide sparsity in %)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
